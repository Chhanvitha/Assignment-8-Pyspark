{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6a8a7d8-3e37-4c59-b3b6-f1a6539993ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffddc70e-3390-4784-89bb-f5e34929ca3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1416f996-5773-455a-a601-259460011b9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|pickup_longitude|pickup_latitude|RatecodeID|store_and_fwd_flag|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n|       1|    01-03-2016 00:00|     01-03-2016 00:07|              1|          2.5|    -73.97674561|    40.76515198|         1|                 N|     -74.00426483|     40.74612808|           1|        9.0|  0.5|    0.5|      2.05|         0.0|                  0.3|       12.35|\n|       1|    01-03-2016 00:00|     01-03-2016 00:11|              1|          2.9|    -73.98348236|    40.76792526|         1|                 N|      -74.0059433|     40.73316574|           1|       11.0|  0.5|    0.5|      3.05|         0.0|                  0.3|       15.35|\n|       2|    01-03-2016 00:00|     01-03-2016 00:31|              2|        19.98|    -73.78202057|    40.64480972|         1|                 N|     -73.97454071|     40.67576981|           1|       54.5|  0.5|    0.5|       8.0|         0.0|                  0.3|        63.8|\n|       2|    01-03-2016 00:00|     01-03-2016 00:00|              3|        10.78|    -73.86341858|    40.76981354|         1|                 N|     -73.96965027|     40.75776672|           1|       31.5|  0.0|    0.5|      3.78|        5.54|                  0.3|       41.62|\n|       2|    01-03-2016 00:00|     01-03-2016 00:00|              5|        30.43|    -73.97174072|    40.79218292|         3|                 N|      -74.1771698|      40.6950531|           1|       98.0|  0.0|    0.0|       0.0|        15.5|                  0.3|       113.8|\n+--------+--------------------+---------------------+---------------+-------------+----------------+---------------+----------+------------------+-----------------+----------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/Volumes/workspace/default/nyc_data/yellow_tripdata_2016-03.csv\", header=True, inferSchema=True)\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "047e1d69-99a8-41bc-945f-a90e66a3b5d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Query 1: Add a “Revenue” Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a9f80cf-61ed-490e-8271-c1f20b76b479",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = df.withColumn(\"Revenue\", \n",
    "    col(\"fare_amount\") + col(\"extra\") + col(\"mta_tax\") + \n",
    "    col(\"improvement_surcharge\") + col(\"tip_amount\") + \n",
    "    col(\"tolls_amount\") + col(\"total_amount\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f75c4a11-e0bc-4ea4-a3e5-e359b9e8fea4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " Query 2: Increasing Count of Total Passengers by Area (Grouped by Pickup Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20521424-8856-425f-9d41-f36c56cb5d8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+----------------+\n|pickup_lon_area|pickup_lat_area|total_passengers|\n+---------------+---------------+----------------+\n|         -73.87|          40.98|               0|\n|         -73.95|          40.87|               0|\n|         -74.23|          40.53|               0|\n|         -73.77|          40.64|               1|\n|         -73.91|          40.64|               1|\n|         -73.97|          40.84|               1|\n|         -73.81|          40.97|               1|\n|         -73.73|          40.95|               1|\n|         -73.89|          40.89|               1|\n|         -73.88|          40.85|               1|\n|         -73.97|           40.6|               1|\n|          -73.9|          40.65|               1|\n|         -74.19|          40.68|               1|\n|         -73.81|           40.9|               1|\n|         -73.95|           40.9|               1|\n|         -73.85|          40.87|               1|\n|         -74.01|          40.62|               1|\n|         -74.35|          40.71|               1|\n|         -73.85|          40.82|               1|\n|         -74.01|          40.77|               1|\n+---------------+---------------+----------------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import round, sum\n",
    "\n",
    "df.groupBy(\n",
    "    round(col(\"pickup_longitude\"), 2).alias(\"pickup_lon_area\"),\n",
    "    round(col(\"pickup_latitude\"), 2).alias(\"pickup_lat_area\")\n",
    ").agg(sum(\"passenger_count\").alias(\"total_passengers\")) \\\n",
    " .orderBy(col(\"total_passengers\").asc()) \\\n",
    " .show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d272e3f3-d804-4f58-890d-6d1a7f78d60c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Query 3: Real-time Average Fare & Total Earning by 2 Vendors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bef027d-c7d7-44eb-9789-539f6bb65ed1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-----------------+\n|VendorID|avg_fare|avg_total_earning|\n+--------+--------+-----------------+\n|       1|   12.25|            15.46|\n|       2|   12.67|            15.97|\n+--------+--------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, round\n",
    "\n",
    "df.groupBy(\"VendorID\") \\\n",
    "  .agg(\n",
    "    round(avg(\"fare_amount\"), 2).alias(\"avg_fare\"),\n",
    "    round(avg(\"total_amount\"), 2).alias(\"avg_total_earning\")\n",
    "  ) \\\n",
    "  .show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cca3c9b4-444f-4218-b7ff-78967928bc93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Query 4: Moving Count of Payments Made by Each Payment Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaa7d9f8-e185-4c98-a6b8-705dc5e93ee6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp, window, col, count\n",
    "\n",
    "df_with_time = df.withColumn(\n",
    "    \"pickup_time\",\n",
    "    to_timestamp(col(\"tpep_pickup_datetime\"), \"dd-MM-yyyy HH:mm\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dec65a0-f82f-4eab-b957-f518126f871a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-------------+\n|              window|payment_type|payment_count|\n+--------------------+------------+-------------+\n|{2016-03-01 00:00...|           1|         4500|\n|{2016-03-01 00:00...|           4|           13|\n|{2016-03-01 00:00...|           2|         2522|\n|{2016-03-01 00:00...|           3|           44|\n|{2016-03-01 01:00...|           1|         2500|\n|{2016-03-01 01:00...|           3|           18|\n|{2016-03-01 01:00...|           2|         1617|\n|{2016-03-01 01:00...|           4|           13|\n|{2016-03-01 02:00...|           3|           19|\n|{2016-03-01 02:00...|           2|         1089|\n|{2016-03-01 02:00...|           1|         1491|\n|{2016-03-01 02:00...|           4|            3|\n|{2016-03-01 03:00...|           2|          862|\n|{2016-03-01 03:00...|           1|          977|\n|{2016-03-01 03:00...|           3|           16|\n|{2016-03-01 03:00...|           4|            5|\n|{2016-03-01 04:00...|           2|          891|\n|{2016-03-01 04:00...|           3|           17|\n|{2016-03-01 04:00...|           1|         1011|\n|{2016-03-01 04:00...|           4|           10|\n+--------------------+------------+-------------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df_with_time.groupBy(\n",
    "    window(\"pickup_time\", \"1 hour\"),  # adjust as needed\n",
    "    \"payment_type\"\n",
    ").agg(count(\"*\").alias(\"payment_count\")) \\\n",
    " .orderBy(\"window\") \\\n",
    " .show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f60bacc6-e32f-4ac1-b525-f28a88ecbc39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Query 5: Top 2 Vendors by Revenue on a Date, with Passenger Count & Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b41eaffe-6faf-436f-9547-3a33540e3158",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+----------------+--------------+\n|VendorID|total_revenue|total_passengers|total_distance|\n+--------+-------------+----------------+--------------+\n+--------+-------------+----------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "df_filtered = df.withColumn(\"trip_date\", to_date(\"tpep_pickup_datetime\", \"MM-dd-yyyy HH:mm\"))\n",
    "\n",
    "df_filtered.filter(col(\"trip_date\") == \"2016-03-01\") \\\n",
    "    .groupBy(\"VendorID\") \\\n",
    "    .agg(\n",
    "        sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        sum(\"passenger_count\").alias(\"total_passengers\"),\n",
    "        sum(\"trip_distance\").alias(\"total_distance\")\n",
    "    ) \\\n",
    "    .orderBy(col(\"total_revenue\").desc()) \\\n",
    "    .limit(2) \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "421a9f8e-2c81-41be-b60e-3c2f76734035",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Query 6: Most Passengers Between a Route of Two Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5319601d-395b-429a-8247-22ef637e2f71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+-----------+----------------+\n|pickup_lon|pickup_lat|dropoff_lon|dropoff_lat|total_passengers|\n+----------+----------+-----------+-----------+----------------+\n|       0.0|       0.0|        0.0|        0.0|           18876|\n+----------+----------+-----------+-----------+----------------+\nonly showing top 1 row\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\n",
    "    round(col(\"pickup_longitude\"), 2).alias(\"pickup_lon\"),\n",
    "    round(col(\"pickup_latitude\"), 2).alias(\"pickup_lat\"),\n",
    "    round(col(\"dropoff_longitude\"), 2).alias(\"dropoff_lon\"),\n",
    "    round(col(\"dropoff_latitude\"), 2).alias(\"dropoff_lat\")\n",
    ").agg(sum(\"passenger_count\").alias(\"total_passengers\")) \\\n",
    " .orderBy(col(\"total_passengers\").desc()) \\\n",
    " .show(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36b66c12-8f83-4bc4-ac2a-6a8c412285a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Query 7: Top Pickup Locations in Last 5/10 Seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fe6d973-6f16-4679-8cd3-9e39a2a0d1e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "df = df.withColumn(\"pickup_time\", to_timestamp(\"tpep_pickup_datetime\", \"dd-MM-yyyy HH:mm\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5317518a-1628-43f2-a714-9bc6d754b020",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+----------------+\n|pickup_longitude|pickup_latitude|total_passengers|\n+----------------+---------------+----------------+\n|    -73.98389435|    40.75371552|               6|\n|    -73.98871613|    40.74850082|               6|\n|    -73.98594666|    40.75743103|               6|\n|    -73.98747253|    40.71986008|               6|\n|    -73.99058533|     40.7493248|               6|\n|    -73.98401642|    40.76475525|               6|\n|     -73.9460907|    40.77297974|               6|\n|    -73.97637177|    40.74420547|               5|\n|    -73.98356628|    40.72583008|               5|\n|     -73.9523468|    40.80366898|               5|\n|    -74.00266266|    40.71846008|               5|\n|    -73.87091827|     40.7737999|               5|\n|    -73.96340942|    40.77112961|               5|\n|    -73.99378967|    40.72467041|               5|\n|    -73.97901917|    40.75924683|               5|\n|    -73.98064423|    40.73390961|               5|\n|    -73.98265076|    40.73122787|               5|\n|    -73.96913147|    40.74990082|               5|\n|    -73.98166656|    40.73683548|               5|\n|    -73.98007202|    40.74596024|               5|\n+----------------+---------------+----------------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import unix_timestamp, max as max_, sum, col, lit\n",
    "\n",
    "df = df.withColumn(\"pickup_time\", to_timestamp(\"tpep_pickup_datetime\", \"dd-MM-yyyy HH:mm\"))\n",
    "\n",
    "# Step 2: Find latest pickup time\n",
    "latest_time = df.select(max_(\"pickup_time\")).first()[0]\n",
    "\n",
    "# Step 3: Filter last 10 seconds of data\n",
    "df.filter(\n",
    "    unix_timestamp(\"pickup_time\") >= unix_timestamp(lit(latest_time)) - 10\n",
    ").groupBy(\n",
    "    \"pickup_longitude\", \"pickup_latitude\"\n",
    ").agg(\n",
    "    sum(\"passenger_count\").alias(\"total_passengers\")\n",
    ").orderBy(\n",
    "    col(\"total_passengers\").desc()\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a943dfb4-7b3f-42a6-9de9-e5c9ebb51de4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "NYC_Taxi_Analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}